### Задание.
Попробуйте оценить какие-нибудь свои или чужие программы, которые выполняют объёмную вычислительную работу -- какова мера их сложности, как сильно растёт время их работы по мере увеличения входных данных? Напишите небольшой отчёт.

### Ответ
На одной из прошлых работ у нас существовал калькулятор тарифа для потенциальных клиентов. В нем я обнаружил место расчета одного из показателей, для которого выгружались почти все данные из бд и через циклы происходил расчет. 

Расчет выглядел, как три вложенных цикла, которые создавали результирующий массив с несколькими уровнями вложенности. Результирующий массив передавался дальше по коду, мог изменяться.

Таких мест, где использовался данный массив, наверно, было около 5-7.

Операция создания данного массива или его обход будет иметь сложность O(n^3), потому что обход будет включать 3 вложенных цикла.

Попробовал провести эксперимент. 

Имеем массив с двумя уровнями вложенности: на 1 уровне - 100, 1000, 10000 элементов. Размер второго уровня постоянный - 100 элементов.
```
$result = [];
$count = 1000000;
$subCount = 100;
for ($i = 1; $i <= $count; $i++) {
	for ($g = 1; $g <= $subCount; $g++) {
		$result[$i][$g] = 1;
	}
}
```
Результаты:

100 - 0 сек

1000 - 0 сек

10000 - 7 сек

К сожалению, на большее кол-во элементов даже не хватает 10Gb памяти.

Если предположить, что дальнейшее увеличение элементов первого уровня в 10 раз будет приводить к увеличению времени в 7 раз, получаем, что вложенные циклы уже дают как минимум O(n * n), возможно и даже экспоненциальный рост.

К удивлению обнаружил, что чем больше элементов на втором уровне вложенности, тем быстрее заполняется память.



